randomSeed=1
maxThreads=32
trainOnDev=false
errorExampleExtractor=FirstTokenSpan

evaluation=F(mode=MACRO_WEIGHTED, filterLabel=true, Beta=1)
evaluation=Precision(weighted=false, filterLabel=true)
evaluation=Recall(weighted=false, filterLabel=true)
evaluation=Accuracy()
evaluation=Accuracy(computeBaseline=true)

gridSearchParameterValues=l2(0,.1,.01,.001)

feature_dep=NGramDep(scale=INDICATOR, mode=ParentsAndChildren, useRelationTypes=true, minFeatureOccurrence=2, n=1, cleanFn=PolyStemCleanFn, tokenExtractor=AllTokenSpans)
feature_sent1=NGramSentence(scale=NORMALIZED_TFIDF, minFeatureOccurrence=2, n=1, cleanFn=PolyStemCleanFn, tokenExtractor=AllTokenSpans)
feature_sent2=NGramSentence(scale=NORMALIZED_TFIDF, minFeatureOccurrence=2, n=2, cleanFn=PolyStemCleanFn, tokenExtractor=AllTokenSpans)
feature_doc1=NGramSentence(scale=NORMALIZED_TFIDF, minFeatureOccurrence=2, n=1, cleanFn=PolyStemCleanFn, tokenExtractor=AllDocumentSentenceInitialTokens)

feature_ner=Ner(useTypes=true, tokenExtractor=AllTokenSpans)

feature_phr1=NGramContext(scale=INDICATOR, contextWindowSize=0, minFeatureOccurrence=2, n=1, cleanFn=PolyDefaultCleanFn, tokenExtractor=FirstTokenSpan)
feature_aff5=NGramContext(clusterer=AffixMaxLength5, scale=INDICATOR, contextWindowSize=0, minFeatureOccurrence=2, n=1, cleanFn=PolyDefaultCleanFn, tokenExtractor=FirstTokenSpan)
feature_phrh1=NGramContext(scale=INDICATOR, contextWindowSize=0, minFeatureOccurrence=2, n=1, cleanFn=PolyDefaultCleanFn, tokenExtractor=FirstTokenSpanLastToken)
feature_affh5=NGramContext(clusterer=AffixMaxLength5, scale=INDICATOR, contextWindowSize=0, minFeatureOccurrence=2, n=1, cleanFn=PolyDefaultCleanFn, tokenExtractor=FirstTokenSpanLastToken)

model=Areg(l1=0, l2=0, convergenceEpsilon=-1, maxDataSetRuns=3, batchSize=10, evaluationIterations=500, maxEvaluationConstantIterations=2000)
{
	validLabels=None
}
